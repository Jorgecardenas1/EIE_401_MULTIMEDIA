{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a22500b-75f6-4e9e-bff8-e2166e04bd6a",
   "metadata": {},
   "source": [
    "<h1><center>\n",
    "\n",
    "</center></h1>\n",
    "<font size=\"6\"><center>\n",
    "EIE 401\n",
    "PROCESAMIENTO DIGITAL MULTIMEDIA \n",
    "</center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb821ab-49e9-40ef-8ecd-d491bba9452c",
   "metadata": {},
   "source": [
    "\n",
    "<center><h2>Actividad 6</h2></center>\n",
    "<center><h3>Audio</h3></center>\n",
    "<center><h3>Profesor: Jorge Cardenas</h3></center>\n",
    "\n",
    "<center><h3>Por: _______</h3></center>\n",
    "<center><h5>Pontificia Universidad Catolica de Valparaiso</h5></center>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0889ee3-d16b-49e3-be4b-a4c94f28701d",
   "metadata": {},
   "source": [
    "## 1. Operaciones para extracción de características.\n",
    "\n",
    "### 1.1 Con un audio (voz o música) no mayor a 30 segundos, utilizando la libreria Librosa (https://librosa.org/), numpy, pytorch, implementa operaciones fundamentales como: \n",
    "- Media\n",
    "- Kurtosis\n",
    "- Skewness\n",
    "- Zero Crossing Rate \n",
    "- Spectral Centroid\n",
    "- Energía\n",
    "- RMSE\n",
    "- Frecuencia fundamental\n",
    "<p align=\"justify\">\n",
    "Estas operaciones son fundamentales en el proceso de extracción de características. Explica el resultado obtenido y que significa cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab6ee5-d7a3-4cf7-9aee-1d1a76b5525f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb8294e2",
   "metadata": {},
   "source": [
    "## 2. Implementaciones\n",
    "\n",
    "### 2.1 Utilizando Pytorch Audio obtenga el espectrograma del audio original\n",
    "El espectrograma debe producirse para valores número de muestras para la transformada rápida de fourier de  32, 128, 512. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf800d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c2d43d8",
   "metadata": {},
   "source": [
    "### 2.2 Utilizando Pytorch audio y Librosa, implementa Mel Frequency Cepstral Coefficients (MFCCs) (opcional)\n",
    "\n",
    "Sigue el siguiente ejemplo (https://www.kaggle.com/code/ilyamich/mfcc-implementation-and-tutorial) y explica que significa el resultado obtenido, graficando los coeficientes en un espectrograma. Investiga sobre Cepstral Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf35251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64b67c8",
   "metadata": {},
   "source": [
    "### 3. Audio Processing\n",
    "### 3.1 En matlab, del paquete de procesamiento de audio, debes elegir una función de la librería, estudiarla y hacer un ejemplo.\n",
    "\n",
    "Debes enviar un informe en PDF de 1 (una) página explicando, el algoritmo seleccionado, como funciona y el ejemplo que desarrollaste. Incluye por lo menos un gráfico que demuestre el trabajo realizado. \n",
    "\n",
    "Debes subir a tu repositorio el código en matlab con dicha solución.\n",
    "\n",
    "En el sitio  https://la.mathworks.com/help/audio/index.html?s_tid=CRUX_lftnav y https://la.mathworks.com/help/audio/audio-processing-algorithm-design.html, encuentras diferentes funciones para generar efectos como reverberancia o control de la onda (compresores, gates, etc)\n",
    "\n",
    "Así mismo, en el sitio https://la.mathworks.com/help/signal/measurements-and-feature-extraction.html, encuentras ejemplos para extracción de caracteristicas de la señal de audio, por ejemplo métricas de pulso y de transición.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb0add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3add46e0-f5e2-4a20-8830-3e795f78d2a0",
   "metadata": {},
   "source": [
    "## 5. Referencias\n",
    "<p align=\"justify\">\n",
    "    \n",
    "[Análisis espectral para audio] https://ccrma.stanford.edu/~jos/mdft/mdft-python.html\n",
    "\n",
    "[Análisis espectral] https://currents.soest.hawaii.edu/ocn_data_analysis/_static/Spectrum.html\n",
    "\n",
    "[MFCC]https://medium.com/@derutycsl/intuitive-understanding-of-mfccs-836d36a1f779\n",
    "\n",
    "[Cepstrum]https://www.kuniga.me/blog/2021/12/11/pitch-via-cepstrum.html\n",
    "\n",
    "[LPC] https://www.youtube.com/watch?v=DIr6SPdK4NA\n",
    "\n",
    "[LPC] https://www.kuniga.me/blog/2021/05/13/lpc-in-python.html\n",
    "\n",
    "[MFCC] https://librosa.org/doc/0.10.1/generated/librosa.feature.mfcc.html#librosa.feature.mfcc\n",
    "\n",
    "[MFCC] https://pytorch.org/audio/main/generated/torchaudio.transforms.MFCC.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c4aa4-b5cb-4e20-96af-ab7d37ec4bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
